{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from __future__ import (absolute_import, division, print_function, unicode_literals)\n",
    "#import absolute_import\n",
    "\n",
    "import pywt \n",
    "import urllib.request, urllib.error, urllib.parse\n",
    "import json\n",
    "import numpy as np\n",
    "import statsmodels.tsa.stattools as stats\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import pprint\n",
    "from datetime import datetime as dt\n",
    "from dateutil.relativedelta import relativedelta as dlta\n",
    "#import tensorflow as tf\n",
    "import matplotlib.pyplot as plot\n",
    "import skfuzzy as fuzz\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.tsa.stattools as ts\n",
    "import time\n",
    "from prices import fullprices\n",
    "\n",
    "#import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "#import pycwt as wavelet\n",
    "#from pycwt.helpers import find\n",
    "from matplotlib.image import NonUniformImage\n",
    "\n",
    "from pandas.stats.api import ols\n",
    "\n",
    "class PairsTrader(object):\n",
    "    def __init__(self):\n",
    "        self.df = {}#pd.DataFrame()\n",
    "        #self.periods = [12,1,2,3,4,5,6,9,24,48]#months\n",
    "        self.mvadays = 10\n",
    "        #note: notebook saves in current directory (paths are not relative)\n",
    "        #self.hdf_path = \"pairs.h5\"\n",
    "        self.coints = []\n",
    "        self.limits = [.93,1.069,.931,1.07] # [buyTight,unTighten,unLoosen,buyLoose] i.e. [.94,.99,1.01,1.06] conservative [.94,1.05,.95,1.06] aggressive\n",
    "        self.cash = 1000.00 # starting cash\n",
    "        self.debug = False\n",
    "        self.confs = [\"1%\",\"5%\",\"10%\"] # confidence intervals we want, when we run Augmented Dicky-Fuller\n",
    "        self.startDate=\"2016-05-01\"\n",
    "        self.endDate=\"2017-04-28\"\n",
    "        self.stocks = ['CTSH','ADP','PYPL','YHOO','AVGO','EBAY','GLW','MU','VMW','PSX','APC','HAL','WMB','VLO','MPC','BHI','SE','DVN','APA','CB','MMC','BBT','CME','STT','EQR','AFL','ALL','DFS','BEN','AAL','EMR','CSX','DE','ITW','ETN','NSC','WM','CMI','SYK','BDX','HUM','VRTX','CAH','HCA','ILMN','BAX','MYL','BXLT','TSLA','CBS','CCL','LVS','FOX','TRI','DISH','VIA','MDLZ','COST','CL','KHC','KMB','RAI','KR','GIS','ADM','EL']           \n",
    "        self.prices = []\n",
    "        self.pairs = []    \n",
    "        self.corr = .95\n",
    "        self.wavelet_corr=.85 #using waveletes to smooth price and test correlation\n",
    "        self.results=[]\n",
    "        \n",
    "    def getPairs(self):\n",
    "        self.prices=fullprices()\n",
    "        print(len(self.prices),len(self.stocks))\n",
    "        wv_corr=0.0\n",
    "        #YAHOO API having network issues, stored all these prices in prices.py\n",
    "#        for ticker in self.stocks:\n",
    "#            print(\"ticker: \",ticker)\n",
    "#            time.sleep(1)\n",
    "#            tickerPrices = y.Share(ticker).get_historical(self.startDate,self.endDate)\n",
    "#            cleanPrices =[]\n",
    "#            for j in tickerPrices: cleanPrices.append(float(j['Adj_Close']))\n",
    "#            if self.debug: print(\"cleanPrices: \",cleanPrices)\n",
    "#            self.prices.append(cleanPrices[::-1])#reverse prices, most recent at end of list\n",
    "#            print(self.prices)\n",
    "        print(\"len: \",len(self.prices[0]))\n",
    "        j=1\n",
    "        for i in range(len(self.stocks)):\n",
    "            for j in range(i+1,len(self.stocks)):\n",
    "                try:#catching the diff lengths exception\n",
    "                    #wv_corr=self.waveletCalc([self.prices[i],self.prices[j]])\n",
    "                    if self.debug: print(\"wv_corr: \",wv_corr)\n",
    "                    if(np.corrcoef(self.prices[i],self.prices[j])[1,0] > self.corr):# and wv_corr>self.wavelet_corr:\n",
    "                        print(\"corr found: \",self.stocks[i],self.stocks[j])\n",
    "                        self.pairs.append([self.stocks[i],self.stocks[j]])\n",
    "                except:\"\"\n",
    "        print(\"pairs: \",self.pairs,\"num Pairs: \",len(self.pairs))\n",
    "              \n",
    "    def runPairs(self,fuzzy=True):\n",
    "        for i in self.pairs:\n",
    "            prc1=self.prices[self.stocks.index(i[0])]\n",
    "            prc2=self.prices[self.stocks.index(i[1])]\n",
    "            if self.debug: print(\"prc1: \",prc1)\n",
    "            if self.debug: print(\"prc2: \",prc2)\n",
    "            tic1,tic2=i[0],i[1]\n",
    "            if prc2[0]>prc1[0]: \n",
    "                prc1,prc2=prc2,prc1#keep higher price on top, logic in tradePairs expects this\n",
    "                tic1,tic2=tic2,tic1\n",
    "            self.tradePairs(prc1,prc2,tic1,tic2,fuzzy)\n",
    "    \n",
    "    def tradePairs(self,prc1,prc2,tic1,tic2,fuzzy=True):\n",
    "        # stor averages, look for deviations away from average,\n",
    "        # expect cointegration relationship to pull them back to normal\n",
    "        buyLong=buyShort=sellLong=sellShort=profit=highLoose=totBuys=totSells=buyDiff=chProfit=mProfit=0.0\n",
    "        lowTight=100.0\n",
    "        cash = self.cash\n",
    "        df = self.df\n",
    "        days = self.mvadays\n",
    "        limits = self.limits\n",
    "        \n",
    "        perceptron([prc1,prc2])\n",
    "        \n",
    "        gc1,gc2=self.gc([prc1,prc2])\n",
    "        bla1,bla2=self.bla([prc1,prc2])\n",
    "        fuzz1=self.fuzzy(gc1,bla1)\n",
    "        fuzz2=self.fuzzy(gc2,bla2)\n",
    "        \n",
    "        #calculating percentages to put in leader and follower stocks\n",
    "        #note: 100.0-leadernumber represents we are putting the majority in the follower stocks\n",
    "        perc1=1.0-fuzz1*(1.0/(fuzz1+fuzz2))\n",
    "        perc2=1.0-fuzz2*(1.0/(fuzz1+fuzz2))\n",
    "        \n",
    "        #flag to turn off fuzzy logic, to compare results\n",
    "        if not fuzzy:\n",
    "            perc1=perc2=.5 #even distro, normal pairs trading\n",
    "            \n",
    "        print(\"fuzz1,fuzz2: \",fuzz1,fuzz2)\n",
    "        print(\"perc1,perc2: \",perc1,perc2)\n",
    "        \n",
    "        #playing around with leader/follower percentages\n",
    "        if not fuzzy:\n",
    "            perc1=perc2=.5 #even distro, normal pairs trading\n",
    "        #perc1,perc2=1.0,0.0 #all first stock\n",
    "        #perc1,perc2=0.0,1.0 #all second stock\n",
    "        \n",
    "        #self.wavCohere([prc1,prc2])\n",
    "        \n",
    "        if self.debug: print(\"prc1: \",prc1)\n",
    "        if self.debug: print(\"prc2: \",prc2)\n",
    "        \n",
    "        if prc1.__len__()!=prc2.__len__():\n",
    "            print(\"len mismatch\")\n",
    "            return\n",
    "        \n",
    "        #display vars\n",
    "        dmvas=[]\n",
    "        cashbals=[]\n",
    "        buysellsigs=[] # to show on the graph if we're long or short\n",
    "        \n",
    "        tight=loose=lastDay=False\n",
    "        for i in range(prc1.__len__()):\n",
    "            if i==len(prc1)-1: lastDay=False#True #Taking out last day logic for now, simply make True to cash out on last day\n",
    "            if i<days:\n",
    "              dmvas.append(0)\n",
    "              cashbals.append(cash/100.0)\n",
    "              buysellsigs.append(5)#neutral\n",
    "              continue#days needed to calc moving average\n",
    "            mmavg=np.array(prc1[i-days:i]).mean()\n",
    "            cmavg=np.array(prc2[i-days:i]).mean()\n",
    "            dmavg=mmavg-cmavg\n",
    "            dmvas.append(dmavg)\n",
    "            cashbals.append(cash/100.0)\n",
    "            diff=prc1[i]-prc2[i]\n",
    "            \n",
    "            if self.debug: print(\"prc1,mmavg,prc2,cmavg,diff,dmavg,dratio: \",prc1[i],mmavg,prc2[i],cmavg,(prc1[i]-prc2[i]),dmavg,diff/dmavg,buyDiff,limits[1]*dmavg)\n",
    "            \n",
    "            if(diff/dmavg < lowTight):lowTight=diff/dmavg\n",
    "            if(diff/dmavg > highLoose):highLoose=diff/dmavg\n",
    "            \n",
    "            #detect a tight relationship, long the upper price and short the lower price\n",
    "            #cannot be in tight or loose relationship to execute\n",
    "            if((not tight and not loose) and diff<limits[0]*dmavg):\n",
    "                if self.debug: print(\"buying tight\",diff/dmavg)\n",
    "                tight=True\n",
    "                buyLong=prc1[i]\n",
    "                sellShort=prc2[i]\n",
    "                \n",
    "                if self.debug: print(\"Long prc1 at: \",prc1[i])\n",
    "                if self.debug: print(\"Short prc2 at: \",prc2[i])\n",
    "                \n",
    "                buyDiff=diff\n",
    "                totBuys+=1\n",
    "                buysellsigs.append(6)\n",
    "            #detect a loose relationship, short the upper price and long the lower price\n",
    "            #cannot be in tight or loose relationship to execute\n",
    "            elif((not loose and not tight) and diff>limits[3]*dmavg):\n",
    "                if self.debug: print(\"buying loose\",diff/dmavg)\n",
    "                loose=True\n",
    "                sellShort=prc1[i]\n",
    "                buyLong=prc2[i]\n",
    "                \n",
    "                if self.debug: print(\"Short prc1 at: \",prc1[i])\n",
    "                if self.debug: print(\"Long prc2 at: \",prc2[i])\n",
    "                \n",
    "                buyDiff=diff\n",
    "                totBuys+=1\n",
    "                buysellsigs.append(4)\n",
    "            #in tight, look for a sell signal \n",
    "            elif(tight and diff>limits[1]*dmavg) or (lastDay and tight):\n",
    "                if lastDay: print(\"lastDay, untightening\")\n",
    "                if self.debug: print(\"untighten\",diff/dmavg)\n",
    "                tight = False\n",
    "                sellLong=prc1[i]\n",
    "                buyShort=prc2[i]\n",
    "                mProfit+=sellLong-buyLong\n",
    "                chProfit+=sellShort-buyShort\n",
    "                \n",
    "                #handling cash\n",
    "                if self.debug: print(\"cash before: \",cash)\n",
    "                cash = ((cash*perc1) * (sellLong/buyLong)) + ((cash*perc2) * (sellShort/buyShort))\n",
    "                #cash = cash * sellLong/buyLong #all money in prc1\n",
    "                if self.debug: print(\"prc1 buy,sell prices,delta: \",buyLong,sellLong,sellLong-buyLong)\n",
    "                if self.debug: print(\"prc2 buy,sell prices,delta: \",buyShort,sellShort,sellShort-buyShort)\n",
    "                if self.debug: print(\"new cash: \",cash)\n",
    "                \n",
    "                buyLong=buyShort=sellLong=sellShort=0.0\n",
    "                totSells+=1\n",
    "                buysellsigs.append(5)\n",
    "            #in loose, look for a sell signal\n",
    "            elif(loose and diff<limits[2]*dmavg) or (lastDay and loose):\n",
    "                if lastDay: print(\"lastDay, unloosening\")\n",
    "                if self.debug: print(\"unloose\",diff/dmavg)\n",
    "                loose = False\n",
    "                buyShort=prc1[i]\n",
    "                sellLong=prc2[i]\n",
    "                mProfit+=sellShort-buyShort\n",
    "                chProfit+=sellLong-buyLong\n",
    "                \n",
    "                #handling cash\n",
    "                if self.debug: print(\"cash before: \",cash)\n",
    "                cash = ((cash*perc2) * (sellLong/buyLong)) + ((cash*perc1) * (sellShort/buyShort))\n",
    "                #cash = cash * sellShort/buyShort #all money in prc1\n",
    "                if self.debug: print(\"prc2 buy,sell prices,delta: \",buyLong,sellLong,sellLong-buyLong)\n",
    "                if self.debug: print(\"prc1 buy,sell prices,delta: \",buyShort,sellShort,sellShort-buyShort)\n",
    "                if self.debug: print(\"new cash: \",cash)\n",
    "                \n",
    "                buyLong=buyShort=sellLong=sellShort=0.0\n",
    "                totSells+=1\n",
    "                buysellsigs.append(5)\n",
    "            #no buy/sell triggers this cycle\n",
    "            elif(tight):\n",
    "                if self.debug: print(\"Still tight, waiting to untighten\",diff/dmavg)\n",
    "                buysellsigs.append(6)\n",
    "            elif(loose):\n",
    "                if self.debug: print(\"Still loose, waiting to unloosen\",diff/dmavg)\n",
    "                buysellsigs.append(4)\n",
    "            else:\n",
    "                if self.debug: print(\"All quiet\",diff/dmavg)\n",
    "                buysellsigs.append(5)\n",
    "        print(\"\\n\",tic1,\"-\",tic2,\"Pairs trading results...\")\n",
    "        print(\"highLoose: \",highLoose)\n",
    "        print(\"lowTight: \",lowTight)\n",
    "        print(\"total buys: \",totBuys)\n",
    "        print(\"total sells: \",totSells)\n",
    "        print(tic1,\" profit%: \",mProfit/np.mean(prc1))\n",
    "        print(tic2,\" profit%: \",chProfit/np.mean(prc2))\n",
    "        #print(\"total profit: \",chProfit+mProfit)\n",
    "        print(\"Note: Final percentages will not match change in cash, because each stock is allocated a different percentage of captial.  See perc1,perc2 above\")\n",
    "        print(\"Beginning cash: \",self.cash)\n",
    "        print(\"Final cash: \",cash)\n",
    "        \n",
    "        plt=plot\n",
    "        plt.plot(prc1, label=str(tic1+\" price\"), linewidth=5.0)\n",
    "        plt.plot(prc2, label=str(tic2+\" price\"), linewidth=5.0)\n",
    "        plt.plot(cashbals, label=str(\"cash balance\"), linewidth=5.0)\n",
    "        plt.plot(dmvas,label=str(str(self.mvadays)+\" day moving average\"), linewidth=5.0)\n",
    "        plt.plot(buysellsigs,label=str(\"long or short\"), linewidth=5.0)\n",
    "        #plt.title(str(pairs[0] + \" \" + pairs[1] + \" Deltas\"),fontsize=20.0)\n",
    "        #plt.xticks([2,19],[self.startDate,self.endDate])\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        self.results.append([tic1,tic2,cash/self.cash,gc1,gc2,bla1,bla2,fuzz1,fuzz2,perc1,perc2])\n",
    "   \n",
    "    def finalResults(self):\n",
    "        return self.results\n",
    "    \n",
    "    #This class uses Google Tensorflow to test for cointegration\n",
    "    #tensorflow will create a single level neural net, where each perceptron is checking for cointegration for the given time interval\n",
    "    '''\n",
    "    def runTensorflow(self):\n",
    "        df = self.df\n",
    "        periods = self.periods\n",
    "        cadfs=[]\n",
    "        coints=[]\n",
    "        \n",
    "        sess = tf.Session()\n",
    "        \n",
    "        #creating perceptrons - one for each cointegration test\n",
    "        #above we specify we are testing for prc1/prc2 prices for : 1M,2M,3M,4M,5M,6M,9M and 12M\n",
    "        for i in periods:\n",
    "          ms = df[\"prc1\"+str(i)]\n",
    "          cs = df[\"prc2\"+str(i)]\n",
    "          \n",
    "          #Creating and running perceptron(ms,cs)\n",
    "          #Note: the perceptron code is located outside this class, because it is serialized\n",
    "          #Since Python classes are also serialized this avoids serializing twice\n",
    "          inp = tf.constant([ms,cs])\n",
    "          y = tf.py_func(perceptron, [inp], tf.float32)\n",
    "          print(\"sess: \", sess.run(y))\n",
    "          coints.append(sess.run(y))\n",
    "          \n",
    "        self.coints = coints\n",
    "        return coints\n",
    "    '''\n",
    "    \n",
    "    def testCoints(self):\n",
    "        pass\n",
    "    \n",
    "    def adfs(self):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "        \n",
    "    def gc(self,x):\n",
    "        if len(x[0]) != len(x[1]): \n",
    "            print(\"error, causality test must be same size arrays!\")\n",
    "            return (-1.0,-1.0)\n",
    "        \n",
    "        #convert two arrays to an array of pairs of tuples\n",
    "        gtest=[]\n",
    "        gtest2=[]\n",
    "        for i in range(len(x[0])):\n",
    "            gtest.append((x[0][i],x[1][i]))#gtest is done with an array of tuples\n",
    "            gtest2.append((x[1][i],x[0][i]))#reverse to test gc the other direction\n",
    "        if self.debug: print(\"gtest: \",gtest)\n",
    "        if self.debug: print(\"gtest2: \",gtest2)\n",
    "        \n",
    "        #running test, here we go!!!\n",
    "        s = stats.grangercausalitytests(gtest,5)#5 is numLags\n",
    "        s2 = stats.grangercausalitytests(gtest2,5)\n",
    "        if self.debug: print(\"s: \",s)\n",
    "        if self.debug: print(\"s2: \",s2)\n",
    "        \n",
    "        #getting lowest p-score for all lags, p-score less than 0.05 allows us to reject null of no causality\n",
    "        #test, just pulling first lag, usually the lowest\n",
    "        gc1=s[1][0]['params_ftest'][1]#,s[2]['params_ftest'][0],s[3]['params_ftest'][0],s[4]['params_ftest'][0],s[5]['params_ftest'][0])#max of 5 lags of gcs\n",
    "        gc2=s2[1][0]['params_ftest'][1]#,s2[2]['params_ftest'][0],s2[3]['params_ftest'][0],s2[4]['params_ftest'][0],s2[5]['params_ftest'][0])#max of 5 lags of gcs\n",
    "        \n",
    "        #pulling lowest of 5 lags, p-scores (usually its the first lag, but not always)\n",
    "        gc1=min(s[1][0]['params_ftest'][1],s[2][0]['params_ftest'][1],s[3][0]['params_ftest'][1],s[4][0]['params_ftest'][1],s[5][0]['params_ftest'][1])#max of 5 lags of gcs\n",
    "        gc2=min(s2[1][0]['params_ftest'][1],s2[2][0]['params_ftest'][1],s2[3][0]['params_ftest'][1],s2[4][0]['params_ftest'][1],s2[5][0]['params_ftest'][1])#max of 5 lags of gcs\n",
    "        \n",
    "        print(\"gc1: \",gc1)\n",
    "        print(\"gc2: \",gc2)\n",
    "        return gc1,gc2\n",
    "    \n",
    "    def waveletCalc(self,x):\n",
    "        print(\"wave test\")\n",
    "        #discrete wavelet transform\n",
    "        wv1,wv2=x[0],x[1]\n",
    "        wv1_dwt_ca,wv1_dwt_cd = pywt.dwt(wv1,'db2')#haar, morl\n",
    "        wv2_dwt_ca,wv2_dwt_cd = pywt.dwt(wv2,'db2')#haar, morl\n",
    "        print(\"wv after\")\n",
    "        #modwt (), stationary wavelet transform\n",
    "        #obtaining approximation coefficients (similar to values of wavelet) and details coefficients, (changes)\n",
    "        \n",
    "        db2 = pywt.Wavelet('db2')#daubechies 2 \n",
    "        ca_cd1= pywt.swt(wv1, db2, level=1,start_level=0)\n",
    "        ca_cd2= pywt.swt(wv2, db2, level=1,start_level=0)\n",
    "        wv1_ca,wv1_cd=ca_cd1[0][0],ca_cd1[0][1]\n",
    "        wv2_ca,wv2_cd=ca_cd2[0][0],ca_cd2[0][1]\n",
    "        \n",
    "        wv_corr=np.corrcoef(wv1,wv2)[1,0]\n",
    "        swt_ca_corr=np.corrcoef(wv1_ca,wv2_ca)[1,0]\n",
    "        swt_cd_corr=np.corrcoef(wv1_cd,wv2_cd)[1,0]\n",
    "        print(\"corr Orig Wavelets: \",wv_corr)\n",
    "        print(\"corr SWT approx Coeffs: \",swt_ca_corr)\n",
    "        print(\"corr SWT details Coeffs: \",swt_cd_corr)\n",
    "        \n",
    "        return swt_cd_corr\n",
    "    \n",
    "    def bla(self,x):#brim leadership ratio\n",
    "        p1,p2=x[0],x[1]\n",
    "        diff = 0.0\n",
    "        diffs = []\n",
    "        #diffavg = np.abs((np.sum(p1) - np.sum(p2)) / p1.__len__()) * 1.0\n",
    "        diffavg = 0.0\n",
    "        move = 0.0\n",
    "        p1move = 0.0\n",
    "        p2move = 0.0\n",
    "        p1moves = []\n",
    "        p2moves = []\n",
    "        p1diff = 0.0\n",
    "        p2diff = 0.0\n",
    "\n",
    "        if ((p1.__len__() != p2.__len__()) or (p1.__len__() < 6) or (p2.__len__() < 6)):\n",
    "            #print \"Array Lengths must match and be great than 6 and exact same size\"\n",
    "            return 0.0,0.0,0.0,0.0\n",
    "        brimfuzzy = 0\n",
    "        brimfuzzy2 = 0\n",
    "        for i in range(5,p1.__len__()):\n",
    "            ###print \"i: \",i\n",
    "            diffavg = np.abs((np.sum(p1[i-5:i-1]) / 5.0) - (np.sum(p2[i-5:i-1]) / 5.0))\n",
    "            ##print \"diffavg: \",diffavg\n",
    "            diff = np.abs(p1[i] - p2[i]) * 1.0\n",
    "            ##print \"diff: \",diff\n",
    "            diffs.append(diff)\n",
    "            move = np.abs(diff - diffavg) * 1.0\n",
    "            ##print \"move: \", move\n",
    "            p1diff = np.abs(p1[i] - p1[i-1]) * 1.0\n",
    "            p2diff = np.abs(p2[i] - p2[i-1]) * 1.0\n",
    "            ##print \"p1diff: \",p1diff\n",
    "            ##print \"p2diff: \",p2diff\n",
    "            if (p1diff == 0.0): p1move=0.0\n",
    "            else: p1move = move / (p1diff * 1.0)\n",
    "            if (p2diff == 0.0): p2move=0.0\n",
    "            else: p2move = move / (p2diff * 1.0)\n",
    "            ##print \"p1move: \",p1move\n",
    "            ##print \"p2move: \",p2move\n",
    "            p1moves.append(p1move)\n",
    "            p2moves.append(p2move)\n",
    "        ##print \"\\n\\np1: \",p1\n",
    "        ##print \"p2: \",p2\n",
    "        ##print \"diffs: \",diffs\n",
    "        ##print \"p1moves: \",p1moves\n",
    "        ##print \"p2moves: \",p2moves\n",
    "        p1leadscore = (np.sum(p1moves) / p1.__len__())\n",
    "        p2leadscore = (np.sum(p2moves) / p2.__len__())\n",
    "        p1leadratio = (np.sum(p1moves) / p1.__len__()) / (np.sum(p2moves) / p2.__len__())\n",
    "        p2leadratio = (np.sum(p2moves) / p2.__len__()) / (np.sum(p1moves) / p1.__len__())\n",
    "        if(p1leadratio < 1.1 and p1leadratio > .9):#FIXME, no movements could be detected as leader\n",
    "            brimfuzzy+=1\n",
    "        if(p2leadratio < 1.05 and p2leadratio > .95):\n",
    "            brimfuzzy2+=1\n",
    "\n",
    "        print(\"p1lead,p2lead,p1ratio,p2ratio: \",p1leadscore,p2leadscore,p1leadratio,p2leadratio)\n",
    "\n",
    "        #return p1leadscore,p2leadscore,p1leadratio,p2leadratio,brimfuzzy,brimfuzzy2\n",
    "        return p1leadratio,p2leadratio\n",
    "    \n",
    "    #wavelet coherence, \n",
    "    #cross wavelet transform\n",
    "    def wavCohere(self,x):\n",
    "        s1,s2=x[0],x[1]\n",
    "        dt=1.0\n",
    "        W12, cross_coi, freq, signif = wavelet.xwt(s1, s2, dt, dj=1/12, s0=-1, J=-1,significance_level=0.8646, wavelet='morlet',normalize=True)\n",
    "    \n",
    "    def fuzzy(self,gc=.001,bla=1.2):\n",
    "    \n",
    "        #scale gc and bla to 1-10 scale\n",
    "        newgc=0.0\n",
    "        newbla=0.0\n",
    "        \n",
    "        if(gc>.09): \n",
    "            newgc=0.0\n",
    "        elif(gc<0.0):\n",
    "            newgc=0.0\n",
    "        else:\n",
    "            newgc=(0.1-gc)*100\n",
    "                 \n",
    "        if(bla>2.0):\n",
    "            newbla=10.0\n",
    "        else:\n",
    "            newbla=bla*5.0\n",
    "                  \n",
    "        print(\"gc,newgc: \",gc,newgc)\n",
    "        print(\"bla,newbla: \",bla,newbla)\n",
    "        \n",
    "        #gc lo 0.0-0.05, med 0.5-1.0, high 1.0-infinity\n",
    "        #bla  lo med ..5- or 1.1-1.2, high med .9-1.1,\n",
    "        \n",
    "        # Generate universe variables\n",
    "        #   * gcity and blaice on subjective ranges [0, 10]\n",
    "        #   * lead has a range of [0, 25] in units of percentage points\n",
    "        x_gc = np.arange(0, 11, 1)\n",
    "        x_bla = np.arange(0, 11, 1)\n",
    "        x_lead  = np.arange(0, 11, 1)\n",
    "        \n",
    "        # Generate fuzzy membership functions\n",
    "        gc_lo = fuzz.trimf(x_gc, [0, 0, 3])\n",
    "        gc_md = fuzz.trimf(x_gc, [3, 5, 7])\n",
    "        gc_hi = fuzz.trimf(x_gc, [7, 10, 10])\n",
    "        bla_lo = fuzz.trimf(x_bla, [0, 0, 3])\n",
    "        bla_md = fuzz.trimf(x_bla, [3, 5, 7])\n",
    "        bla_hi = fuzz.trimf(x_bla, [7, 10, 10])\n",
    "        lead_lo = fuzz.trimf(x_lead, [0, 0, 3])\n",
    "        lead_md = fuzz.trimf(x_lead, [3, 5, 7])\n",
    "        lead_hi = fuzz.trimf(x_lead, [7, 10, 10])\n",
    "        \n",
    "        #Visualize1\n",
    "        \n",
    "        # We need the activation of our fuzzy membership functions at these values.\n",
    "        # The exact values 6.5 and 9.8 do not exist on our universes...\n",
    "        # This is what fuzz.interp_membership exists for!3\n",
    "        # it doesn't matter that 6.5 is the same for lo md hi, it just cant be a number in the definition set above\n",
    "        \n",
    "        gc_level_lo = fuzz.interp_membership(x_gc, gc_lo, newgc)\n",
    "        gc_level_md = fuzz.interp_membership(x_gc, gc_md, newgc)\n",
    "        gc_level_hi = fuzz.interp_membership(x_gc, gc_hi, newgc)\n",
    "        \n",
    "        bla_level_lo = fuzz.interp_membership(x_bla, bla_lo, newbla)\n",
    "        bla_level_md = fuzz.interp_membership(x_bla, bla_md, newbla)\n",
    "        bla_level_hi = fuzz.interp_membership(x_bla, bla_hi, newbla)\n",
    "        \n",
    "        # Now we take our rules and apply them. Rule 1 concerns bad food OR blaice.\n",
    "        # The OR operator means we take the maximum of these two.\n",
    "        active_rule1 = np.fmax(gc_level_lo, bla_level_lo)\n",
    "        \n",
    "        # Now we apply this by clipping the top off the corresponding output\n",
    "        # membership function with `np.fmin`\n",
    "        lead_activation_lo = np.fmin(active_rule1, lead_lo)  # removed entirely to 0\n",
    "        \n",
    "        # For rule 2 we connect acceptable blaice to medium leadping\n",
    "        lead_activation_md = np.fmin(bla_level_md, lead_md)\n",
    "        \n",
    "        # For rule 3 we connect high blaice OR high food with high leadping\n",
    "        active_rule3 = np.fmax(gc_level_hi, bla_level_hi)\n",
    "        lead_activation_hi = np.fmin(active_rule3, lead_hi)\n",
    "        lead0 = np.zeros_like(x_lead)\n",
    "        #\n",
    "        \n",
    "        #Visualize2\n",
    "        \n",
    "        # Aggregate all three output membership functions together\n",
    "        aggregated = np.fmax(lead_activation_lo,\n",
    "                             np.fmax(lead_activation_md, lead_activation_hi))\n",
    "        \n",
    "        # Calculate defuzzified result\n",
    "        lead = fuzz.defuzz(x_lead, aggregated, 'centroid')\n",
    "        lead_activation = fuzz.interp_membership(x_lead, aggregated, lead)  # for plot\n",
    "        print(\"lead: \",lead)\n",
    "        return lead\n",
    "    \n",
    "    def saveHdf(self):\n",
    "        pass\n",
    "        #need to clean this up self.df.to_hdf(self.hdf_path,'random',mode='a')5\n",
    "        \n",
    "def perceptron(x):\n",
    "    # print \"perceptron prc1: \",x[0]\n",
    "    # print \"perceptron prc2: \",x[1]\n",
    "  \n",
    "    confs=[\"1%\",\"5%\",\"10%\"]\n",
    "    pdf = pd.DataFrame()\n",
    "    pdf[\"prc1\"]=x[0]\n",
    "    pdf[\"prc2\"]=x[1]\n",
    "    \n",
    "    res = ols(x=pdf[\"prc1\"],y=pdf[\"prc2\"])\n",
    "    print(\"res: \",res)\n",
    "    beta_hr = res.beta.x\n",
    "    pdf[\"res\"] = pdf[\"prc1\"] - beta_hr*pdf[\"prc2\"]\n",
    "\n",
    "    print(\"beta_hr: \",beta_hr)\n",
    "    #print \"pdf.res: \",pdf[\"res\"]\n",
    "    \n",
    "    adf = ts.adfuller(pdf[\"res\"])\n",
    "    pprint.pprint(adf)\n",
    "    #cadfs.append(adf)\n",
    "    print(\"cadf: \",adf)\n",
    "    coints=[]\n",
    "    for key in confs:coints.append(np.float32(adf[4][key]))\n",
    "      \n",
    "    print(\"perceptron coints: \",coints)\n",
    "\n",
    "    #self.cadfs = cadfs\n",
    "    return [coints]\n",
    "    #return x\n",
    "  \n",
    "\n",
    "    \n",
    "def main():\n",
    "    trader = PairsTrader()\n",
    "    #trader.buildData()\n",
    "    trader.getPairs()\n",
    "    trader.runPairs()\n",
    "    trader.runPairs(False)\n",
    "    print(trader.finalResults())\n",
    "    #caedfs = trader.runTensorflow()\n",
    "    #pprint.pprint(cadfs)\n",
    "    #trader.trade()\n",
    "    trader.saveHdf()\n",
    "\n",
    "if __name__==\"__main__\":main()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
